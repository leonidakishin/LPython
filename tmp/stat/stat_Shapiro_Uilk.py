# Написал программу, чтобы поиграть с критерием Шапиро-Уилка на примере с игральными костями.
# Задаем число костей и количество бросков.
# Случайная величина - сумма очков для каждого броска.
# Программа строит гистограмму и рассчитывает p для критерия Шапиро-Уилка
# (показан в заголовке гистограммы).
# Если кубик один, то распределение "ненормальное" (равномерное).
# С увеличением числа костей должно приближаться к нормальному.
# Заметил, однако, странную закономерность.
# При увеличении числа бросков гистограмма, как и ожидал, становится более гладкой
# и визуально приближается к кривой нормального распределения, но p уменьшается
# и при больших N этот критерий приводит к ошибке первого рода.
# Например, для 5 костей, ошибка стабильно происходит при N > 300.
# Для 10 костей - при числе бросков больше приблизительно 700.


# @Denis_Kazakov, Во первых: Спасибо за проделанную работу, код утащил себе поиграться. А во вторых никаких странностей в поведении программы нет. Кубики изначально дают ненормальное  распределение. Проблема в интерпретации р. Высокий р не делает гипотезу о нормальном распределении верной. Критерий  говорит что у нас недостаточно данных чтобы отказаться от нее, а "кривость" гистограммы,  при небольшом числе бросков, это просто случайность, вполне вероятная и при нормальном распределении. По мере накопления данных, визуально кажется что гистограмма бросков кубика все менее и менее "кривая", но математике все сложнее и сложнее списывать "кривизну" гистограммы на случайность => р уменьшается. И когда данных накапливается достаточно гипотеза о том что кубики порождают нормальное распределение идет на юг.


# @Denis_Kazakov, ОК. У нас есть "черный ящик" который выдает нам набор из n (от 3х до максимального числа бросков) случайных чисел. Для каждого набора в отдельности ваша программа считает p-value.  то есть пытается "понять" может ли этот набор чисел быть выборкой из нормального распределения  или же это выборка из "ненормального" распределения. И да чем больше кубиков участвует в одном броске тем меньше получающееся распределение отличается от нормального и тем больше нужно бросков чтобы отвергнуть нулевую гипотезу.  Чтобы проще было прейдем к монетке. Представим что у нас очень кривая монета и всегда падает орлом. Через 5 бросков возникнут первые сомнения, через 25 будет уверенность что она точно(хотя это не верно) кривая. Ну а после 100 орлов подряд сомнения отпадут совсем. А если шанс выпадения орла 0,51 то  и тысячи бросков не хватит чтобы прийти к выводу о кривизне монетки.

# с увеличением числа кубиков распределение должно приближаться к нормальному - именно так, но оно так и останется ненормальным.

# Именно об этом и говорит центральная предельная теорема - так и есть

# И именно поэтому нам надо все больше и больше бросков чтобы отличие "кубикового" распределения от нормального стало статистически значимым.

# К сожалению я не настолько знаком с питоном чтобы внести исправления в код. Но было бы интересно посмотреть на график р-валуе когда не каждый раз новая серия бросков генерится. А генерится вся серия из мах бросков ,  а потом срезами формируются выборки от 3 до мах. как при этом ведет себя р=валуе.


import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


n_dice = int(input("Введите число костей "))
n_throws = int(input("Введите число бросков "))

# Число столбиков в гистограмме
n_bins = 20

# Генерируем набор случайных чисел и суммируем для каждого броска
rng = np.random.default_rng()
throwing = rng.integers(1, high=6, size=(n_throws, n_dice), endpoint=True)
X = np.sum(throwing, axis=1) / n_dice

# Расчет критерия Шапиро-Уилка
shapiro_test = stats.shapiro(X)

# Строим график
figure_title = "p = {0}\n W = {1}".format(shapiro_test.pvalue, shapiro_test.statistic)
fig = plt.hist(X, bins=n_bins)
plt.xlabel("Среднее для одного броска")
plt.title(figure_title)
plt.grid(True)
plt.show()
